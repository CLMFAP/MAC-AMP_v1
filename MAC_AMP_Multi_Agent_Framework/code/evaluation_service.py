import json
from typing import List, Dict, Any
import time
import os
import subprocess
import gzip
import pickle
import glob
import pandas as pd
import numpy as np
import ast
from Bio.PDB import PDBParser
import logging
logging.basicConfig(level=logging.ERROR)
import torch
from evaluation_biopython import biopython_protein_analysis
import math
import re
import tempfile
import sys
from utils.mic_hill_mapping import hill_score_m0_1_a1_from_logmic

def foldseek_similarity_score(evalue: float,
                              alntmscore: float,
                              fident: float,   # 0..1ï¼ˆeasy-search è¾“å‡ºå³å°æ•°ï¼‰
                              qcov: float=None, # 0..1ï¼Œå¯é€‰
                              tcov: float=None  # 0..1ï¼Œå¯é€‰
                              ) -> float:
    """
    çŸ­è‚½å‹å¥½ç‰ˆç»¼åˆåˆ†ï¼š
    - alntmscoreï¼šç”¨ tanh å‹ç¼©ï¼Œé¿å…è¿‡æ—©é¥±å’Œ
    - fidentï¼šç›´æ¥ç”¨ 0..1
    - evalueï¼šå¯¹æ•°ç¼©æ”¾ï¼ˆè¶Šå°è¶Šæ¥è¿‘ 1ï¼‰
    - coverageï¼šqcov/tcov äºŒè€…æœ€å°å€¼ï¼Œå¼±æƒé‡é˜²æ­¢å±€éƒ¨å¯¹é½åˆ·é«˜åˆ†
    """
    # 1) ç»“æ„åˆ†ï¼ˆå»ºè®®æŠŠ 2.0 å½“ä½œâ€œé«˜ç›¸ä¼¼â€çš„å‚è€ƒç‚¹ï¼‰
    score_norm = math.tanh(alntmscore) / math.tanh(2.0)   # â‰ˆ0..1ï¼Œ1~2 ä¹‹é—´ä»æœ‰åŒºåˆ†åº¦
    score_norm = max(0.0, min(score_norm, 1.0))
    # 2) åºåˆ—ä¸€è‡´æ€§ï¼ˆ0..1ï¼‰ï¼Œä¿æŒä¸å˜
    fident_norm = max(0.0, min(float(fident), 1.0))
    # 3) è¦†ç›–åº¦ï¼ˆå¯é€‰ï¼‰
    if qcov is not None and tcov is not None:
        cov = max(0.0, min(min(float(qcov), float(tcov)), 1.0))
    else:
        cov = 1.0  # ç¼ºåˆ—å°±ä¸æƒ©ç½š
    # 4) e-value å¯¹æ•°ç¼©æ”¾ï¼še<=1e-6 ~1ï¼›e>=1e+2 ~0
    if evalue is None or evalue <= 0:
        e_bonus = 1.0
    else:
        x = -math.log10(evalue)           # e=1e-6->6ï¼Œe=1->0ï¼Œe=100->-2
        e_bonus = (x + 2) / 8             # [-2,6] -> [0,1]
        e_bonus = max(0.0, min(e_bonus, 1.0))
    # 5) æƒé‡ï¼ˆçŸ­è‚½ï¼šåºåˆ—ä¸€è‡´æ€§æ›´é‡è¦äº›ï¼‰
    w_score, w_fident, w_cov, w_eval = 0.35, 0.45, 0.10, 0.10
    final = (w_score * score_norm +
             w_fident * fident_norm +
             w_cov   * cov +
             w_eval  * e_bonus)

    return round(final, 3)

def foldseek_compare(
    seqs: List[str],
    ref_pdb_path: str,
    tmp_dir: str = "tmp_foldseek"
) -> List[float]:
    """
    ä½¿ç”¨ OmegaFold é¢„æµ‹æ¯æ¡ query çš„ç»“æ„ï¼Œç„¶åç”¨ foldseek easy-search
    å°† query_pdb ä¸ ref_pdb_pathï¼ˆå¯ä¸ºç›®å½•æˆ–å•PDBï¼‰è¿›è¡Œç»“æ„æ¯”å¯¹ã€‚
    è¿”å›æ¯æ¡ query çš„ similarity_score åˆ—è¡¨ã€‚
    """
    if isinstance(seqs, str):
        try:
            seqs = ast.literal_eval(seqs)
        except (ValueError, SyntaxError):
            return [0.0]

    print(f"[DEBUG] Function: foldseek_compare(easy-search), Input N={len(seqs)}")
    os.makedirs(tmp_dir, exist_ok=True)

    def _clean_seq(s: str) -> str:
        s = s.strip().upper()
        return (s.replace("X", "G")
                 .replace("U", "C")
                 .replace("Z", "E")
                 .replace("J", "L")
                 .replace("B", "D")
                 .replace("O", "K"))

    results = []
    for idx, query_seq in enumerate(seqs):
        record = {
            'sequence': query_seq,
            'status': None,
            'result_file': None,
            'preview': None,
            'error': None,
            'top_hit': None,
            'score': None,     # å°†å¡«å…¥ alntmscore
            'evalue': None,
            'fident': None,
            'similarity_score': None
        }

        # Step 1: å†™ FASTAï¼ˆå¯¹éå¸¸è§æ°¨åŸºé…¸åšè½»é‡æ›¿æ¢ä»¥ä¿è¯ OmegaFold å¯è¿è¡Œï¼‰
        fasta_path = os.path.join(tmp_dir, f"query_{idx}.fa")
        pdb_out_dir = os.path.join(tmp_dir, f"query_pdb_{idx}")
        os.makedirs(pdb_out_dir, exist_ok=True)
        cleaned = _clean_seq(query_seq)
        with open(fasta_path, 'w') as f:
            f.write(f">query{idx}\n{cleaned}\n")
        # Step 2: è¿è¡Œ OmegaFold ç”Ÿæˆ query PDB
        try:
            _ = subprocess.run(
                ["omegafold", "--model", "2", fasta_path, pdb_out_dir],
                check=True,
                capture_output=True,
                text=True
            )
        except subprocess.CalledProcessError as e:
            print(f"âŒ OmegaFold å‡ºé”™ï¼ˆidx={idx}ï¼‰: {query_seq}")
            print("â›” stderr:\n", (e.stderr or "").strip()[:500])
            print("ğŸ“¤ stdout:\n", (e.stdout or "").strip()[:500])
            record['status'] = 'omegafold_failed'
            record['error'] = e.stderr or str(e)
            results.append(record)
            continue

        pdb_files = glob.glob(os.path.join(pdb_out_dir, "*.pdb"))
        if not pdb_files:
            record['status'] = 'no_structure_generated'
            record['error'] = 'OmegaFoldæœªç”Ÿæˆä»»ä½•PDBç»“æ„æ–‡ä»¶'
            results.append(record)
            continue
        query_pdb = pdb_files[0]
        # é‡Šæ”¾æ˜¾å­˜ï¼ˆå¯é€‰ï¼‰
        try:
            torch.cuda.empty_cache()
            torch.cuda.ipc_collect()
        except Exception:
            pass
        # Step 3: ç”¨ foldseek easy-searchï¼ˆç›´æ¥äº§å‡º TSVï¼‰
        tsv_path = os.path.join(tmp_dir, f"foldseek_result_{idx}.tsv")
        try:
            # ref_pdb_path å¯ä»¥æ˜¯ç›®å½•æˆ–å•ä¸ª PDB æ–‡ä»¶
            proc = subprocess.run(
                ["foldseek", "easy-search",
                 query_pdb,
                 ref_pdb_path,
                 tsv_path,
                 tmp_dir,
                 "--threads", "2",
                 "--format-output", "query,target,evalue,alntmscore,fident,qcov,tcov",
                 "--exhaustive-search", "1",
                 "-s", "12",
                 "--max-seqs", "10000",
                 "--prefilter-mode", "1"],
                check=True,
                capture_output=True,
                text=True
            )
            if proc.stdout:
                print(f"[foldseek stdout idx={idx}] {proc.stdout[:2000]}")
            if proc.stderr:
                print(f"[foldseek stderr idx={idx}] {proc.stderr[:2000]}")
        except subprocess.CalledProcessError as e:
            print(f"âŒ Foldseek easy-search å‡ºé”™ï¼ˆidx={idx}ï¼‰: {query_seq}")
            print("â›” stderr:\n", (e.stderr or "").strip()[:2000])
            print("ğŸ“¤ stdout:\n", (e.stdout or "").strip()[:2000])
            record['status'] = 'foldseek_failed'
            record['error'] = e.stderr or str(e)
            results.append(record)
            continue
        # Step 4: è§£æ TSV ç»“æœï¼ˆå– top-1ï¼‰
        try:
            if (not os.path.exists(tsv_path)) or (os.path.getsize(tsv_path) == 0):
                record['status'] = 'no_match'
                record['result'] = 'No significant similarity found.'
                results.append(record)
                continue

            with open(tsv_path, 'r') as f:
                lines = [ln.strip() for ln in f.readlines() if ln.strip()]

            if not lines:
                record['status'] = 'no_match'
                record['result'] = 'No significant similarity found.'
                results.append(record)
                continue

            record['preview'] = lines[:5]
            cols = lines[0].split('\t')  # query, target, evalue, alntmscore, fident
            if len(cols) >= 5:
                record['top_hit'] = cols[1]
                record['evalue'] = float(cols[2]) if cols[2] not in ("", "inf", "nan") else 1.0
                record['score']  = float(cols[3]) if cols[3] not in ("", "inf", "nan") else 0.0
                record['fident'] = float(cols[4]) if cols[4] not in ("", "inf", "nan") else 0.0
                record['similarity_score'] = foldseek_similarity_score(
                    record['evalue'], record['score'], record['fident']
                )
                record['status'] = 'success'
                record['result_file'] = tsv_path
            else:
                record['status'] = 'success_partial'
                record['error'] = f'è¾“å‡ºåˆ—æ•°ä¸è¶³ï¼Œè¡Œå†…å®¹: {lines[0]}'
                record['result_file'] = tsv_path
        except Exception as e:
            record['status'] = 'success_partial'
            record['result_file'] = tsv_path
            record['error'] = f'è§£æTSVå¤±è´¥: {e}'
            print(f'foldseek_compare(easy-search) è§£æå¤±è´¥: {e}')
        results.append(record)

    # print(f'[DEBUG] foldseek_compare(easy-search) ç»“æœæ¡ç›®: {results}')
    similarity_scores = [r['similarity_score'] if r['similarity_score'] is not None else 0.0 for r in results]
    print(f'[DEBUG] foldseek_compare(easy-search) ç»“æœæ¡ç›®: {similarity_scores}')
    return similarity_scores

# 3. MacrelæŠ—èŒè‚½é¢„æµ‹
def macrel_predict(seqs: List[str], model_path: str = "test_macrel/AMP.pkl.gz") -> str:
    """
    ç”¨Macrelæ¨¡å‹é¢„æµ‹å¤šä¸ªæŠ—èŒè‚½åˆ†æ•°
    """
    if isinstance(seqs, str):
        try:
            seqs = ast.literal_eval(seqs)
        except (ValueError, SyntaxError):
            return [{'error': f"æ— æ³•å°†å­—ç¬¦ä¸²å‚æ•°è§£æä¸ºåˆ—è¡¨: {seqs}"}]
            
    # print(f"[DEBUG] è°ƒç”¨å‡½æ•°: macrel_predict, è¾“å…¥: {seqs}")
    print(f"[DEBUG] Function: macrel_predict, Input: {seqs}")
    try:
        import sys
        sys.path.append("test_macrel")
        from predictor import macrel_predictor
        model = pickle.load(gzip.open(model_path, 'rb'))
        scores = macrel_predictor(seqs, model)
        results = [{'sequence': seq, 'score': float(score)} for seq, score in zip(seqs, scores)]
        # return json.dumps({"macrel_predict": results})
        scores_list = [r['score'] if 'score' in r else -1.0 for r in results]
        print(f"[DEBUG] Function: macrel_predict ç»“æœæ¡ç›®: {scores_list}")
        return scores_list
    except Exception as e:

        results = [{'sequence': seq, 'error': str(e)} for seq in seqs]
        return json.dumps(results)
    
def extract_plddt_from_pdb(pdb_file: str) -> float:
    """
    ä»PDBæ–‡ä»¶ä¸­æå–å¹³å‡plDDTå€¼ï¼ˆå‡è®¾plDDTå­˜å‚¨åœ¨B-factorå­—æ®µï¼‰
    """
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("predicted", pdb_file)
    b_factors = [
        atom.get_bfactor()
        for model in structure
        for chain in model
        for residue in chain
        for atom in residue
    ]
    if b_factors:
        return sum(b_factors) / len(b_factors)
    else:
        return -1.0  # è¡¨ç¤ºæœªèƒ½è·å–æœ‰æ•ˆplDDT
# 4. OmegaFoldç»“æ„é¢„æµ‹

def omegafold_predict(seqs: List[str], tmp_dir: str = "tmp_omegafold") -> str:
    """
    ç”¨ OmegaFold é¢„æµ‹å¤šä¸ªç»“æ„ï¼Œè¿”å›æ¯ä¸ª PDB æ–‡ä»¶è·¯å¾„ã€‚
    åœ¨å¤±è´¥æ—¶ä»…æ‰“å°é”™è¯¯ä¿¡æ¯ï¼Œæ­£å¸¸è¿è¡Œæ—¶ä¸æ‰“å°ä»»ä½•æ—¥å¿—ã€‚
    """
    if isinstance(seqs, str):
        try:
            seqs = ast.literal_eval(seqs)
        except (ValueError, SyntaxError):
            return [{'error': f"æ— æ³•å°†å­—ç¬¦ä¸²å‚æ•°è§£æä¸ºåˆ—è¡¨: {seqs}"}]

    os.makedirs(tmp_dir, exist_ok=True)
    results = []

    for idx, seq in enumerate(seqs):
        fasta_path = os.path.join(tmp_dir, f"query_{idx}.fa")
        pdb_out_dir = os.path.join(tmp_dir, f"query_pdb_{idx}")

        with open(fasta_path, 'w') as f:
            f.write(f">query{idx}\n{seq}\n")

        command = ["omegafold", "--model", "2", fasta_path, pdb_out_dir]

        try:
            result = subprocess.run(
                command,
                check=True,
                capture_output=True,
                text=True
            )
        except subprocess.CalledProcessError as e:
            print(f"âŒ OmegaFold å‡ºé”™ï¼ˆåºåˆ— idx={idx}ï¼‰: {seq}")
            print("â›” stderr:")
            print(e.stderr.strip())
            print("ğŸ“¤ stdout:")
            print(e.stdout.strip())
            results.append({'sequence': seq, 'error': f'OmegaFold failed with return code {e.returncode}'})
            continue
        except Exception as e:
            results.append({'sequence': seq, 'error': f'OmegaFold exception: {e}'})
            continue

        pdb_files = glob.glob(os.path.join(pdb_out_dir, "*.pdb"))
        if not pdb_files:
            results.append({'sequence': seq, 'error': 'No PDB file generated by OmegaFold'})
            continue

        pdb_file = pdb_files[0]
        plddt_score = extract_plddt_from_pdb(pdb_file)
        results.append({
            'sequence': seq,
            'pdb_file': pdb_file,
            'plddt': round(plddt_score/100.0, 4)
        })
        torch.cuda.empty_cache()
        torch.cuda.ipc_collect()

    # return json.dumps({"omegafold_predict": results}, indent=2)
    plddts = [r['plddt'] if 'plddt' in r else 0.0 for r in results]
    print(f"[DEBUG] Function: omegafold_predict ç»“æœæ¡ç›®: {plddts}")
    return plddts

# 5. ToxinPred3æ¯’æ€§é¢„æµ‹
def toxinpred3_predict(seqs: List[str], model: int = 2, threshold: float = 0.38) -> str:
    """
    ç”¨toxinpred3å‘½ä»¤è¡Œé¢„æµ‹å¤šä¸ªåºåˆ—çš„æ¯’æ€§ï¼Œæ‰€æœ‰åºåˆ—ä¸€æ¬¡æ€§å†™å…¥åŒä¸€ä¸ªFASTAæ–‡ä»¶ï¼Œæ‰¹é‡é¢„æµ‹ã€‚
    è‹¥è¾“å…¥åºåˆ—è¿‡çŸ­ï¼Œè‡ªåŠ¨è¡¥å……ä¸€æ¡æ ‡å‡†é•¿è‚½ï¼Œä¿è¯ç‰¹å¾æå–ä¸æŠ¥é”™ã€‚
    """
    if isinstance(seqs, str):
        try:
            seqs = ast.literal_eval(seqs)
        except (ValueError, SyntaxError):
            return [{'error': f"æ— æ³•å°†å­—ç¬¦ä¸²å‚æ•°è§£æä¸ºåˆ—è¡¨: {seqs}"}]
            
    # print(f"[DEBUG] è°ƒç”¨å‡½æ•°: toxinpred3_predict, è¾“å…¥: {seqs}")
    print(f"[DEBUG] Function: toxinpred3_predict, Input: {seqs}")
    # è‹¥æœ‰çŸ­åºåˆ—ï¼Œè¡¥å……ä¸€æ¡æ ‡å‡†è‚½ï¼Œé¿å…ç‰¹å¾æå–æŠ¥é”™
    seqs_for_pred = list(seqs)
    need_dummy = any(len(seq) < 10 for seq in seqs)
    if need_dummy:
        seqs_for_pred.append("KLFKFFKDLLGKFLG")
    with tempfile.NamedTemporaryFile(mode='w', suffix='.fa', delete=False) as input_file:
        for i, s in enumerate(seqs_for_pred):
            input_file.write(f">seq{i}\n{s}\n")
        input_path = input_file.name
    with tempfile.NamedTemporaryFile(suffix='.csv', delete=False) as output_file:
        output_path = output_file.name
    try:
        cmd = f"toxinpred3 -i {input_path} -o {output_path} -m {model} -t {threshold}"
        subprocess.run(cmd, shell=True, check=True)
        df = pd.read_csv(output_path)
        results = []
        for i, seq in enumerate(seqs):
            # è‹¥dfè¡Œæ•°ä¸è¶³ï¼Œè¿”å›ç©ºdict
            if i < len(df):
                result = df.iloc[i].to_dict()
            else:
                result = {}
            result['sequence'] = seq
            results.append(result)
        # return json.dumps({"toxinpred3_predict": results}   )
        scores = [r.get("Hybrid Score", -1.0) for r in results]
        print(f"[DEBUG] Function: toxinpred3_predict ç»“æœæ¡ç›®: {scores}")
        return scores

    except Exception as e:
        print("Command failed!")
        if hasattr(e, 'returncode'):
            print("Return code:", e.returncode)
        if hasattr(e, 'cmd'):
            print("Command:", e.cmd)
        if hasattr(e, 'stdout'):
            print("stdout:", e.stdout)
        if hasattr(e, 'stderr'):
            print("stderr:", e.stderr)
        results = [{'sequence': seq, 'error': str(e)} for seq in seqs]
        return json.dumps({"toxinpred3_predict": results})
    finally:
        os.remove(input_path)
        if os.path.exists(output_path):
            os.remove(output_path)


def predict_mic(sequences: List[str],mic_regression_root,default_sign) -> List[float]:
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„ MIC æ¨¡å‹é¢„æµ‹ log10(MIC) å€¼ï¼Œå¹¶å°†å…¶å½’ä¸€åŒ–ä¸º [0,1] çš„æ´»æ€§åˆ†æ•°ã€‚
    è¶Šå°ä»£è¡¨ MIC è¶Šä½ï¼ˆæŠ—èŒæ´»æ€§è¶Šå¼ºï¼‰ï¼Œå½’ä¸€åŒ–åå¾—åˆ†è¶Šé«˜ã€‚
    """
    sys.path.append(mic_regression_root)
    
    try:
        from predict import predict_mic
    except ImportError as e:
        print(f"[é”™è¯¯] å¯¼å…¥ PredictMIC å¤±è´¥: {e}")
        return [0.0] * len(sequences)

    try:
        log_mics = predict_mic(sequences, "EC", mic_regression_root,default_sign)
        print(log_mics)
        # æ˜ å°„ log10(MIC) âˆˆ [-2, 4] åˆ° score âˆˆ [0, 1]
        # mic_scores = [(4.0 - min(max(m, -2.0), 4.0)) / 6.0 for m in log_mics]
        mic = [10**m for m in log_mics]
        print(f"[DEBUG] Function: predict_mic ç»“æœæ¡ç›®: {mic}")
        return mic
    except Exception as e:
        print(f"[é”™è¯¯] MIC æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
        return [0.0] * len(sequences)
    
def predict_mic_score(sequences: List[str], mic_regression_root, default_sign) -> List[float]:
    sys.path.append(mic_regression_root)
    
    try:
        from predict import predict_mic
    except ImportError as e:
        print(f"[é”™è¯¯] å¯¼å…¥ PredictMIC å¤±è´¥: {e}")
        return [0.0] * len(sequences)

    try:
        log_mics = predict_mic(sequences, "EC", mic_regression_root, default_sign)
        print("[DEBUG] log_mics:", log_mics)

        mic_scores = hill_score_m0_1_a1_from_logmic(log_mics, default_sign)
        # mic_scores = np.asarray(mic_scores, dtype=float).tolist()

        print(f"[DEBUG] Function: predict_mic_score ç»“æœæ¡ç›®: {mic_scores}")
        return mic_scores
    except Exception as e:
        print(f"[é”™è¯¯] MIC æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
        return [0.0] * len(sequences)

# class Evaluator():
#     def __init__(self,use_default_reward,amp_generator_root,mic_regression_root,default_sign,workspace_dir ):
#         self.use_default_reward = use_default_reward
#         self.amp_generator_root=amp_generator_root
#         self.mic_regression_root=mic_regression_root
#         self.default_sign=default_sign
#         self.workspace_dir=workspace_dir
class Evaluator():
    def __init__(
        self,
        use_default_reward,
        amp_generator_root,
        mic_regression_root,
        default_sign,
        workspace_dir,
        ablation_mode: int = 0,
    ):
        self.use_default_reward = use_default_reward
        self.amp_generator_root = amp_generator_root
        self.mic_regression_root = mic_regression_root
        self.default_sign = default_sign
        self.workspace_dir = workspace_dir

        # è®°å½•æ¶ˆèæ¨¡å¼
        self.ablation_mode = ablation_mode

        # Va: ToxinPred3.0     Vb: OmegaFold
        # Sb: Macrel å¯¹ RL reward çš„è´¡çŒ®ï¼ˆåé¢å•ç‹¬åœ¨ reward å‡½æ•°é‡Œå¤„ç†ï¼‰
        self.disable_va = ablation_mode in (2, 4, 6, 7)  # éœ€è¦æŠŠ Va è®¾ä¸º N/A
        self.disable_vb = ablation_mode in (1, 4, 5, 7)  # éœ€è¦æŠŠ Vb è®¾ä¸º N/A
        self.manual_reward_no_sb = ablation_mode in (3, 5, 6, 7)  # Sb æ¶ˆè â†’ reward=(Sa+Sc)/2
        print(f"disable_va: {self.disable_va}")
        print(f"disable_vb: {self.disable_vb}")
        print(f"manual_reward_no_sb: {self.manual_reward_no_sb}")

            
    def run_evaluation_tools(self, sequences: List[str], ref_pdb_path: str = "/data/AMP_Escherichia_coli_811_new/ref_pdbs") -> Dict:
        print(f"--- [Evaluation Agent]ï¼šEvaluation Start - {len(sequences)} Sequences ---")
        timings = {}
        ref_pdb_path=self.amp_generator_root+ref_pdb_path
        tmp_foldseek=self.amp_generator_root+"/tmp_foldseek"
        macrel_model_path=self.amp_generator_root+"/test_macrel/AMP.pkl.gz"
        tmp_omegafold=self.amp_generator_root+"/tmp_omegafold"
        if self.workspace_dir:
            tmp_omegafold=self.workspace_dir+"/tmp_omegafold"

        try:
            start = time.time()
            phys_chem_results = json.loads(biopython_protein_analysis(seqs=sequences)).get("biopython_protein_analysis", [])
            timings['Biopython'] = time.time() - start
        except Exception as e:
            print(f"[è­¦å‘Š] Biopythonåˆ†æå¤±è´¥: {e}")
            phys_chem_results = [{"error": str(e)}] * len(sequences)

        # --- Va: ToxinPred3.0 ---
        if self.disable_va:
            print("[Ablation] Va (ToxinPred3.0) è¢«å…³é—­ï¼Œtoxicity_results è®¾ä¸º 'N/A'")
            toxicity_results = ["N/A"] * len(sequences)
            timings['ToxinPred3'] = 0.0
        else:
            try:
                start = time.time()
                toxicity_results = toxinpred3_predict(seqs=sequences)
                timings['ToxinPred3'] = time.time() - start
            except Exception as e:
                print(f"[è­¦å‘Š] ToxinPred3é¢„æµ‹å¤±è´¥: {e}")
                toxicity_results = [-1.0] * len(sequences)


        try:
            start = time.time()
            antimicrobial_results = macrel_predict(seqs=sequences, model_path=macrel_model_path)
            timings['Macrel'] = time.time() - start
        except Exception as e:
            print(f"[è­¦å‘Š] Macrelé¢„æµ‹å¤±è´¥: {e}")
            antimicrobial_results = [-1.0] * len(sequences)

        # --- Vb: OmegaFold ---
        if self.disable_vb:
            print("[Ablation] Vb (OmegaFold) è¢«å…³é—­ï¼Œstructure_results è®¾ä¸º 'N/A'")
            structure_results = ["N/A"] * len(sequences)
            timings['OmegaFold'] = 0.0
        else:
            try:
                start = time.time()
                structure_results = omegafold_predict(seqs=sequences, tmp_dir=tmp_omegafold)
                timings['OmegaFold'] = time.time() - start
            except Exception as e:
                print(f"[è­¦å‘Š] OmegaFoldé¢„æµ‹å¤±è´¥: {e}")
                structure_results = [-1.0] * len(sequences)


        try:
            start = time.time()
            similarity_results = foldseek_compare(seqs=sequences, ref_pdb_path=ref_pdb_path, tmp_dir=tmp_foldseek)
            timings['Foldseek'] = time.time() - start
        except Exception as e:
            print(f"[è­¦å‘Š] Foldseekæ¯”è¾ƒå¤±è´¥: {e}")
            similarity_results = [-1.0] * len(sequences)


        try:
            start = time.time()
            mic_score = predict_mic_score(sequences,self.mic_regression_root,self.default_sign)
            timings['MIC_Predict'] = time.time() - start
        except Exception as e:
            print(f"[è­¦å‘Š] MICé¢„æµ‹å¤±è´¥: {e}")
            mic_score = [-1.0] * len(sequences)

        try:
            start = time.time()
            mic_original = predict_mic(sequences,self.mic_regression_root,self.default_sign)
            timings['MIC_Predict'] = time.time() - start
        except Exception as e:
            print(f"[è­¦å‘Š] MICé¢„æµ‹å¤±è´¥: {e}")
            mic_original = [-1.0] * len(sequences)

        # æœ€ç»ˆç¡®ä¿æ‰€æœ‰ç»“æœéƒ½åœ¨ [0,1]ï¼Œé¿å… reward å´©æºƒ
        def clip_list(values: List[float]) -> List[float]:
            return [min(max(v, 0.0), 1.0) for v in values]

        # toxicity_results = clip_list(toxicity_results)
        # antimicrobial_results = clip_list(antimicrobial_results)
        # structure_results = clip_list(structure_results)
        # similarity_results = clip_list(similarity_results)
        # mic_results = clip_list(mic_results)

        combined_results = {
            "peptide_sequence": sequences,
            "physicochemical_properties": phys_chem_results,
            "toxicity": toxicity_results,
            "antimicrobial_activity": antimicrobial_results,
            "structure_prediction": structure_results,
            "similarity_analysis": similarity_results,
            "mic_prediction": mic_score,
            "mic_score": mic_score,
            "mic_original": mic_original
        }

        print(f"--- [Evaluation Agent]ï¼šCompleted ---")
        return {"evaluation_result": combined_results, "timings": timings}

    def get_evaluation_outputs_from_agent(self, sequences: List[str]) -> Dict:
        final_message = self.run_evaluation_tools(sequences)
        evaluation_result = final_message["evaluation_result"]
        physicochemical_properties = evaluation_result["physicochemical_properties"]
        toxicity = evaluation_result["toxicity"]
        antimicrobial_activity = evaluation_result["antimicrobial_activity"]
        structure_prediction = evaluation_result["structure_prediction"]
        similarity_analysis = evaluation_result["similarity_analysis"]
        mic_score = evaluation_result["mic_score"]
        mic_original = evaluation_result["mic_original"]
        try:
            return evaluation_result, physicochemical_properties, toxicity, antimicrobial_activity, structure_prediction, similarity_analysis, mic_score, mic_original
        except json.JSONDecodeError:
            print("âŒ æ— æ³•è§£æ agent è¾“å‡º JSONï¼š", final_message)
            return {"evaluation_result": [], "timings": {}}

    def parse_batch_evaluation(self, evaluation_outputs: Dict) -> List[Dict]:
        result = evaluation_outputs
        peptides = []
        for i in range(len(result["peptide_sequence"])):
            peptides.append({
                "sequence": result["peptide_sequence"][i],
                "physicochemical_propertie":result["physicochemical_properties"][i],
                "amp_score": result["antimicrobial_activity"][i],
                "toxicity_score": result["toxicity"][i],
                "plddt_score": result["structure_prediction"][i],
                "similarity_score": result["similarity_analysis"][i],
                "mic_score": result["mic_score"][i],
                "mic_original": result["mic_original"][i]
            })
        return peptides
    
    def extract_overall_score(self, response_text: str) -> float:
        match = re.search(r'\{["\']overall["\']\s*:\s*([0-9.]+)\}', response_text)
        if match:
            score_str = match.group(1)
            try:
                return float(score_str)
            except ValueError:
                raise ValueError(f"è§£æå¤±è´¥ï¼Œæ— æ³•å°†æå–çš„ '{score_str}' è½¬ä¸º float")
        else:
            raise ValueError("æœªæ‰¾åˆ°åŒ…å« 'overall' åˆ†æ•°çš„ JSON æ ¼å¼")

    # def compute_rewards(self, avg_mic_score: float,avg_amp_score:float,llm_overall_score: float) -> float:  
    #     if not self.use_default_reward:                
    #         return compute_rewards(avg_mic_score, avg_amp_score, llm_overall_score)
    #     else:
    #         # def clip01(x: float) -> float:
    #         #     return max(0.0, min(1.0, x))

    #         # def safe_pow(base: float, expv: float, eps: float) -> float:
    #         #     return math.pow(max(base, eps), expv)  # é¿å… 0**è´Ÿæ•° æˆ– 0**0

    #         # wa, wb = 0.45, 0.55   # Stage0 åæ¢ç´¢å¯è®¾ (0.4, 0.6)ï¼›Stage1 å‡è¡¡å¯è°ƒåˆ° (0.5, 0.5)
    #         # eps = 1e-6

    #         # G = safe_pow(avg_mic_score, wa, eps) * safe_pow(avg_amp_score, wb, eps)
    #         # r = G
    #         # return clip01(r)


    #         """
    #         Reward function for AMP generation with three signals Sa, Sb, Sc.

    #         Design goals:
    #         - Emphasize Sa and Sb equally and more than Sc: Sa â‰ˆ Sb > Sc.
    #         - Monotonic, smooth, numerically stable, bounded in [0, 1].
    #         - Encourage 'both-strong' behavior on Sa and Sb via harmonic mean.

    #         Assumptions:
    #         - Inputs are intended to be in [0, 1]. Values outside will be clipped.

    #         Returns:
    #         - A scalar reward in [0, 1].
    #         """

    #         # --- numeric safety & clipping ---
    #         Sa=avg_mic_score
    #         Sb=avg_amp_score
    #         Sc=llm_overall_score

    #         EPS = 1e-8
    #         Sa = 0.0 if Sa is None else Sa
    #         Sb = 0.0 if Sb is None else Sb
    #         Sc = 0.0 if Sc is None else Sc

    #         # Clip to [0,1] for stability and bounded reward
    #         if Sa < 0.0: Sa = 0.0
    #         if Sa > 1.0: Sa = 1.0
    #         if Sb < 0.0: Sb = 0.0
    #         if Sb > 1.0: Sb = 1.0
    #         if Sc < 0.0: Sc = 0.0
    #         if Sc > 1.0: Sc = 1.0

    #         # --- fuse Sa & Sb with harmonic mean (short-board sensitive & monotonic) ---
    #         # H_ab in [0,1]; use EPS to avoid division-by-zero when Sa+Sb=0
    #         H_ab = (2.0 * Sa * Sb) / (Sa + Sb + EPS)

    #         # --- emphasize H_ab over Sc ---
    #         # Weights reflect: Sa â‰ˆ Sb > Sc  â†’ give H_ab higher weight
    #         w_ab = 0.80  # weight on the "A&B" fused objective
    #         w_c  = 0.20  # weight on C (less important but non-negligible)

    #         reward = w_ab * H_ab + w_c * Sc

    #         # reward is already in [0,1] given inputs in [0,1]
    #         # (H_ab âˆˆ [0,1], Sc âˆˆ [0,1], convex combination)
    #         return reward
    def compute_rewards(self, avg_mic_score: float, avg_amp_score: float,
                        llm_overall_score: float) -> float:
        # å¦‚æœæ˜¯ RL Scientist ç”Ÿæˆçš„è‡ªå®šä¹‰ reward ç¯å¢ƒï¼Œèµ°åŸæ¥çš„ JIT ç‰ˆå‡½æ•°
        if not self.use_default_reward:
            return compute_rewards(avg_mic_score, avg_amp_score, llm_overall_score)

        # ==== 1. åŸºç¡€æ•°å€¼é¢„å¤„ç† ====
        Sa = 0.0 if avg_mic_score is None else avg_mic_score
        Sb = 0.0 if avg_amp_score is None else avg_amp_score
        Sc = 0.0 if llm_overall_score is None else llm_overall_score

        # Clip åˆ° [0,1]ï¼ˆæŒ‰ä½ åŸæ¥çš„é€»è¾‘ï¼‰
        Sa = max(0.0, min(1.0, Sa))
        Sb = max(0.0, min(1.0, Sb))
        Sc = max(0.0, min(1.0, Sc))

        EPS = 1e-8

        # ==== 2. é’ˆå¯¹ Macrel (Sb) çš„æ¶ˆè ====
        # å®éªŒ 3: -Sb
        # å®éªŒ 5: -Vb, -Sb
        # å®éªŒ 6: -Va, -Sb
        # å®éªŒ 7: -Va, -Vb, -Sb
        if self.manual_reward_no_sb:
            # ä¸ç”¨ Macrel (Sb)ï¼Œåªç”¨ Sa å’Œ Sc åšç®€å•å¹³å‡
            return 0.5 * Sa + 0.5 * Sc

        # ==== 3. baselineï¼ˆä»¥åŠåªæ¶ˆ Va/Vb çš„å®éªŒ 1,2,4ï¼‰ä¿æŒåŸ reward ====
        H_ab = (2.0 * Sa * Sb) / (Sa + Sb + EPS)
        w_ab = 0.80
        w_c  = 0.20
        reward = w_ab * H_ab + w_c * Sc
        return reward


            

if __name__ == "__main__":
    seqs = ["RRIRRPRLPRPRVPRPRI"]
    phys_chem_results = json.loads(biopython_protein_analysis(seqs=seqs)).get("biopython_protein_analysis", [])
    print(phys_chem_results)








import math, torch

@torch.jit.script
def clip01(x: float) -> float:
    return max(0.0, min(1.0, x))

@torch.jit.script
def to01_from_m11(x: float) -> float:
    return 0.5 * (x + 1.0)

@torch.jit.script
def safe_sigmoid(x: float) -> float:
    return 1.0 / (1.0 + math.exp(-x))

@torch.jit.script
def safe_pow(base: float, expv: float, eps: float) -> float:
    return math.pow(max(base, eps), expv)

@torch.jit.script
def compute_rewards(Sa: float, Sb: float, Sc: float) -> float:
    # Stage 0: è¿›ä¸€æ­¥ä¼˜åŒ–é—¨æ§ä»¥å¢å¼ºç¨³å®šæ€§ä¸å®‰å…¨æ€§
    wa, wb = 0.5, 0.5
    eps = 1e-6
    G = safe_pow(Sa, wa, eps) * safe_pow(Sb, wb, eps)

    Sc01 = to01_from_m11(Sc)
    alpha, tau = 6.0, 0.52  # è°ƒæ•´ Î± ç¨³å®šæ€§ä¸æ§åˆ¶è¾¹ç•Œ
    g = safe_sigmoid(alpha * (Sc01 - tau))

    r = G * g
    return clip01(r)
